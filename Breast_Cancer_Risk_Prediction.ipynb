{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtYX1GAtaR34QRRjZp4owe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAdewunmi/Breast-Cancer-Risk-Prediction-Project/blob/main/Breast_Cancer_Risk_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Breast Cancer Prediction Project\n",
        "\n",
        "We will build a Deep Learning Model that is to be trained on breast cancer autopsy image dataset to predict if a person has breast cancer and if it is benigh or malign.\n",
        "\n",
        "We will be using DenseNet-201 which is a convolution neural network that is 201 layers deep. We can load a pretrained version of the network or we can also retrain the model, which is what we are doing in this project.\n",
        "\n",
        "We will then implement our very own website that will be built using Django framwork and host it on AWS."
      ],
      "metadata": {
        "id": "4rep0Lwg_N8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "utDei0ck-mMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe4db34c-9cad-42bf-ac9a-8674ab5110e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install core ML/CV dependencies\n",
        "\n",
        "!pip install numpy pandas matplotlib tensorflow keras opencv-python Pillow scikit-learn scipy tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgLshPeHxKns",
        "outputId": "b7d56575-d912-4f1a-bad0-4e766b360290"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs all core libraries required for the model training script,\n",
        "# including TensorFlow/Keras, NumPy, Pandas, scikit-learn, OpenCV (cv2),\n",
        "# and Pillow.\n",
        "\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from keras import layers\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n"
      ],
      "metadata": {
        "id": "HA0LmitSwTJ4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Dataset_loader and init benign/malign datasets\n",
        "\n",
        "import os\n",
        "from typing import Tuple, Union, List\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def Dataset_loader(DIR: str, RESIZE: Union[int, Tuple[int, int]], sigmaX: float = 0.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Load all PNG images from a directory, convert them to RGB, resize, and return a NumPy array.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    DIR : str\n",
        "        Directory containing images. Only files with a .png extension (case-insensitive) are loaded.\n",
        "    RESIZE : int | tuple[int, int]\n",
        "        Target size. If an int, images are resized to (RESIZE, RESIZE).\n",
        "        If a tuple, interpret as (width, height) per OpenCV's convention.\n",
        "    sigmaX : float, optional\n",
        "        Standard deviation for Gaussian blur. If > 0, apply cv2.GaussianBlur; default is 0 (no blur).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Array of shape (N, H, W, 3) in uint8 RGB, where N is the number of images.\n",
        "        If the directory has no PNGs, returns an empty array with shape (0, H, W, 3).\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    FileNotFoundError\n",
        "        If the provided directory does not exist.\n",
        "    ValueError\n",
        "        If RESIZE is a tuple with non-positive values.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Uses PIL to read and ensure RGB; uses OpenCV for resizing (INTER_AREA).\n",
        "    - Processing order is deterministic (alphabetical file name sort).\n",
        "    - Consider renaming to `load_dataset` for PEP 8 compliance in future refactors.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> imgs = Dataset_loader(\"/path/to/benign\", 224)\n",
        "    >>> imgs.shape\n",
        "    (N, 224, 224, 3)\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(DIR):\n",
        "        raise FileNotFoundError(f\"Directory not found: {DIR}\")\n",
        "\n",
        "    # Normalize RESIZE into an (width, height) tuple for OpenCV.\n",
        "    if isinstance(RESIZE, int):\n",
        "        target_size: Tuple[int, int] = (RESIZE, RESIZE)\n",
        "    else:\n",
        "        if len(RESIZE) != 2 or RESIZE[0] <= 0 or RESIZE[1] <= 0:\n",
        "            raise ValueError(\"RESIZE tuple must be (width, height) with positive integers.\")\n",
        "        target_size = (int(RESIZE[0]), int(RESIZE[1]))\n",
        "\n",
        "    # Collect .png files only (case-insensitive), sorted for reproducibility\n",
        "    entries: List[str] = sorted(os.listdir(DIR))\n",
        "    png_paths = [\n",
        "        os.path.join(DIR, name)\n",
        "        for name in entries\n",
        "        if os.path.splitext(name)[1].lower() == \".png\"\n",
        "    ]\n",
        "\n",
        "    # Early return with empty (0, H, W, 3) if no PNGs found\n",
        "    if not png_paths:\n",
        "        return np.empty((0, target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "\n",
        "    images = []\n",
        "    for path in tqdm(png_paths, desc=f\"Loading {os.path.basename(DIR) or DIR}\"):\n",
        "        # Read with PIL, enforce RGB\n",
        "        rgb = np.asarray(Image.open(path).convert(\"RGB\"))\n",
        "        # Resize with OpenCV (expects (width, height))\n",
        "        resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
        "        # Optional blur for preprocessing\n",
        "        if sigmaX and sigmaX > 0:\n",
        "            resized = cv2.GaussianBlur(resized, ksize=(0, 0), sigmaX=sigmaX)\n",
        "        images.append(resized.astype(np.uint8))\n",
        "\n",
        "    return np.stack(images, axis=0)\n",
        "\n",
        "# pass RESIZE and fix the typo in the second path\n",
        "benign = Dataset_loader(\n",
        "    \"drive/MyDrive/Colab Notebooks/Breast-Cancer-Risk-Prediction/data/benign\",\n",
        "    224\n",
        ")\n",
        "malign = Dataset_loader(\n",
        "    \"drive/MyDrive/Colab Notebooks/Breast-Cancer-Risk-Prediction/data/malign\",\n",
        "    224\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nbip33j2ozM",
        "outputId": "e115293a-055f-46ee-9c6f-67fa177e3ddc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading benign: 100%|██████████| 112/112 [00:09<00:00, 11.28it/s]\n",
            "Loading malign: 100%|██████████| 127/127 [00:07<00:00, 17.81it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Notebook-friendly unit tests for `Dataset_loader`.\n",
        "\n",
        "Usage\n",
        "-----\n",
        "1) Define `Dataset_loader` in a previous cell (or ensure `src/dataloader.py` is importable).\n",
        "2) Run this cell. You'll get a unittest report in the output.\n",
        "\n",
        "Notes\n",
        "-----\n",
        "- Uses `unittest` (no external CLI needed).\n",
        "- Creates temporary images and folders; cleans up after itself.\n",
        "- Mirrors the original pytest assertions closely.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import unittest\n",
        "import tempfile\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Optional: If you're in a fresh Colab and missing deps used by Dataset_loader,\n",
        "# you may need to install them in a separate cell:\n",
        "# !pip install pillow opencv-python tqdm\n",
        "\n",
        "# Try to access Dataset_loader from the current notebook scope;\n",
        "# if not present, attempt import from src.dataloader.\n",
        "try:\n",
        "    Dataset_loader  # type: ignore  # noqa: F401\n",
        "except NameError:\n",
        "    try:\n",
        "        from src.dataloader import Dataset_loader  # type: ignore\n",
        "    except Exception as e:\n",
        "        raise RuntimeError(\n",
        "            \"Dataset_loader not found. Define it in a previous cell or ensure src/dataloader.py is importable.\"\n",
        "        ) from e\n",
        "\n",
        "\n",
        "def _make_img(path: Path, size=(30, 20), color=(120, 60, 30)):\n",
        "    \"\"\"\n",
        "    Create a simple RGB image and save it to `path` (PNG or JPG based on extension).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    path : Path\n",
        "        Destination file path (extension determines format).\n",
        "    size : tuple[int, int]\n",
        "        (width, height) of the image to create.\n",
        "    color : tuple[int, int, int]\n",
        "        RGB color fill for the created image.\n",
        "    \"\"\"\n",
        "    img = Image.new(\"RGB\", size, color)\n",
        "    img.save(path)\n",
        "\n",
        "\n",
        "class DatasetLoaderNotebookTests(unittest.TestCase):\n",
        "    \"\"\"Unit tests for `Dataset_loader` adapted for a single Colab cell.\"\"\"\n",
        "\n",
        "    def setUp(self):\n",
        "        # Fresh temp directory for each test\n",
        "        self._tmpdir = tempfile.TemporaryDirectory()\n",
        "        self.tmp = Path(self._tmpdir.name)\n",
        "\n",
        "    def tearDown(self):\n",
        "        # Cleanup temp directory\n",
        "        self._tmpdir.cleanup()\n",
        "\n",
        "    def test_load_pngs_and_resize(self):\n",
        "        d = self.tmp / \"images\"\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Two PNGs (including uppercase extension) and one JPG (ignored)\n",
        "        _make_img(d / \"a.png\", size=(50, 40), color=(255, 0, 0))\n",
        "        _make_img(d / \"b.PNG\", size=(40, 50), color=(0, 255, 0))  # case-insensitive\n",
        "        _make_img(d / \"c.jpg\", size=(60, 60), color=(0, 0, 255))  # should be ignored\n",
        "\n",
        "        arr = Dataset_loader(str(d), 224)\n",
        "        self.assertIsInstance(arr, np.ndarray)\n",
        "        self.assertEqual(arr.shape, (2, 224, 224, 3))\n",
        "        self.assertEqual(arr.dtype, np.uint8)\n",
        "\n",
        "    def test_resize_tuple_width_height(self):\n",
        "        d = self.tmp / \"imgs\"\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        _make_img(d / \"x.png\", size=(10, 10))\n",
        "        _make_img(d / \"y.png\", size=(20, 5))\n",
        "\n",
        "        # (width, height) per OpenCV convention\n",
        "        arr = Dataset_loader(str(d), (120, 80))\n",
        "        self.assertEqual(arr.shape, (2, 80, 120, 3))\n",
        "\n",
        "    def test_nonexistent_dir_raises(self):\n",
        "        with self.assertRaises(FileNotFoundError):\n",
        "            Dataset_loader(str(self.tmp / \"no_such_dir\"), 224)\n",
        "\n",
        "    def test_empty_dir_returns_empty_array(self):\n",
        "        d = self.tmp / \"empty\"\n",
        "        d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        arr = Dataset_loader(str(d), 64)\n",
        "        self.assertIsInstance(arr, np.ndarray)\n",
        "        self.assertEqual(arr.shape, (0, 64, 64, 3))\n",
        "\n",
        "\n",
        "# Run tests when the cell executes\n",
        "unittest.main(argv=[\"\"], verbosity=2, exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svIEXWigBopA",
        "outputId": "092ffd7b-988a-4373-c7c7-ec2ac14b4dad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_empty_dir_returns_empty_array (__main__.DatasetLoaderNotebookTests.test_empty_dir_returns_empty_array) ... ok\n",
            "Loading images: 100%|██████████| 2/2 [00:00<00:00, 1287.98it/s]\n",
            "ok\n",
            "test_nonexistent_dir_raises (__main__.DatasetLoaderNotebookTests.test_nonexistent_dir_raises) ... ok\n",
            "Loading imgs: 100%|██████████| 2/2 [00:00<00:00, 1977.98it/s]\n",
            "ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.025s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7a09cc899130>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add class label arrays for benign/malign\n",
        "\n",
        "benign_label = np.zeros(len(benign))\n",
        "malign_label = np.ones(len(malign))"
      ],
      "metadata": {
        "id": "xaOivnvNFJbQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine images and labels into X/Y\n",
        "\n",
        "X = np.concatenate((benign,malign), axis=0)\n",
        "Y = np.concatenate((benign_label, malign_label), axis=0)"
      ],
      "metadata": {
        "id": "7y_LECT-Rtpf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Shuffle dataset and one-hot encode labels\n",
        "\n",
        "s = np.arange(X.shape[0])\n",
        "np.random.shuffle(s)\n",
        "X = X[s]\n",
        "Y = Y[s]\n",
        "Y = to_categorical(Y, num_classes=2)"
      ],
      "metadata": {
        "id": "5FBzeQfiSjFO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}