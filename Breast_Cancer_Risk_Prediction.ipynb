{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1dxrirqBM4Oqx79Ga/oeM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AAdewunmi/Breast-Cancer-Risk-Prediction-Project/blob/main/Breast_Cancer_Risk_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Breast Cancer Prediction Project\n",
        "\n",
        "We will build a Deep Learning Model that is to be trained on breast cancer autopsy image dataset to predict if a person has breast cancer and if it is benigh or malign.\n",
        "\n",
        "We will be using DenseNet-201 which is a convolution neural network that is 201 layers deep. We can load a pretrained version of the network or we can also retrain the model, which is what we are doing in this project.\n",
        "\n",
        "We will then implement our very own website that will be built using Django framwork and host it on AWS."
      ],
      "metadata": {
        "id": "4rep0Lwg_N8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "utDei0ck-mMN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a003230-acf1-47ae-ee81-2a8760a32960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install core ML/CV dependencies\n",
        "\n",
        "!pip install numpy pandas matplotlib tensorflow keras opencv-python Pillow scikit-learn scipy tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgLshPeHxKns",
        "outputId": "7eebc812-14df-4b8d-c2d0-65365f1329da"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras) (0.17.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installs all core libraries required for the model training script,\n",
        "# including TensorFlow/Keras, NumPy, Pandas, scikit-learn, OpenCV (cv2),\n",
        "# and Pillow.\n",
        "\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from keras import layers\n",
        "from tensorflow.keras.applications.densenet import DenseNet201\n",
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
        "import scipy\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "from functools import partial\n",
        "from sklearn import metrics\n",
        "from collections import Counter\n",
        "import json\n",
        "import itertools\n"
      ],
      "metadata": {
        "id": "HA0LmitSwTJ4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement Dataset_loader and init benign/malign datasets\n",
        "\n",
        "import os\n",
        "from typing import Tuple, Union, List\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def Dataset_loader(DIR: str, RESIZE: Union[int, Tuple[int, int]], sigmaX: float = 0.0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Load all PNG images from a directory, convert them to RGB, resize, and return a NumPy array.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    DIR : str\n",
        "        Directory containing images. Only files with a .png extension (case-insensitive) are loaded.\n",
        "    RESIZE : int | tuple[int, int]\n",
        "        Target size. If an int, images are resized to (RESIZE, RESIZE).\n",
        "        If a tuple, interpret as (width, height) per OpenCV's convention.\n",
        "    sigmaX : float, optional\n",
        "        Standard deviation for Gaussian blur. If > 0, apply cv2.GaussianBlur; default is 0 (no blur).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    np.ndarray\n",
        "        Array of shape (N, H, W, 3) in uint8 RGB, where N is the number of images.\n",
        "        If the directory has no PNGs, returns an empty array with shape (0, H, W, 3).\n",
        "\n",
        "    Raises\n",
        "    ------\n",
        "    FileNotFoundError\n",
        "        If the provided directory does not exist.\n",
        "    ValueError\n",
        "        If RESIZE is a tuple with non-positive values.\n",
        "\n",
        "    Notes\n",
        "    -----\n",
        "    - Uses PIL to read and ensure RGB; uses OpenCV for resizing (INTER_AREA).\n",
        "    - Processing order is deterministic (alphabetical file name sort).\n",
        "    - Consider renaming to `load_dataset` for PEP 8 compliance in future refactors.\n",
        "\n",
        "    Examples\n",
        "    --------\n",
        "    >>> imgs = Dataset_loader(\"/path/to/benign\", 224)\n",
        "    >>> imgs.shape\n",
        "    (N, 224, 224, 3)\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(DIR):\n",
        "        raise FileNotFoundError(f\"Directory not found: {DIR}\")\n",
        "\n",
        "    # Normalize RESIZE into an (width, height) tuple for OpenCV.\n",
        "    if isinstance(RESIZE, int):\n",
        "        target_size: Tuple[int, int] = (RESIZE, RESIZE)\n",
        "    else:\n",
        "        if len(RESIZE) != 2 or RESIZE[0] <= 0 or RESIZE[1] <= 0:\n",
        "            raise ValueError(\"RESIZE tuple must be (width, height) with positive integers.\")\n",
        "        target_size = (int(RESIZE[0]), int(RESIZE[1]))\n",
        "\n",
        "    # Collect .png files only (case-insensitive), sorted for reproducibility\n",
        "    entries: List[str] = sorted(os.listdir(DIR))\n",
        "    png_paths = [\n",
        "        os.path.join(DIR, name)\n",
        "        for name in entries\n",
        "        if os.path.splitext(name)[1].lower() == \".png\"\n",
        "    ]\n",
        "\n",
        "    # Early return with empty (0, H, W, 3) if no PNGs found\n",
        "    if not png_paths:\n",
        "        return np.empty((0, target_size[1], target_size[0], 3), dtype=np.uint8)\n",
        "\n",
        "    images = []\n",
        "    for path in tqdm(png_paths, desc=f\"Loading {os.path.basename(DIR) or DIR}\"):\n",
        "        # Read with PIL, enforce RGB\n",
        "        rgb = np.asarray(Image.open(path).convert(\"RGB\"))\n",
        "        # Resize with OpenCV (expects (width, height))\n",
        "        resized = cv2.resize(rgb, target_size, interpolation=cv2.INTER_AREA)\n",
        "        # Optional blur for preprocessing\n",
        "        if sigmaX and sigmaX > 0:\n",
        "            resized = cv2.GaussianBlur(resized, ksize=(0, 0), sigmaX=sigmaX)\n",
        "        images.append(resized.astype(np.uint8))\n",
        "\n",
        "    return np.stack(images, axis=0)\n",
        "\n",
        "# pass RESIZE and fix the typo in the second path\n",
        "benign = Dataset_loader(\n",
        "    \"drive/MyDrive/Colab Notebooks/Breast-Cancer-Risk-Prediction/data/benign\",\n",
        "    224\n",
        ")\n",
        "malign = Dataset_loader(\n",
        "    \"drive/MyDrive/Colab Notebooks/Breast-Cancer-Risk-Prediction/data/malign\",\n",
        "    224\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Nbip33j2ozM",
        "outputId": "3e6d763c-09c5-435c-d461-8f30f2a43040"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading benign: 100%|██████████| 112/112 [00:05<00:00, 19.89it/s]\n",
            "Loading malign: 100%|██████████| 127/127 [00:04<00:00, 26.45it/s]\n"
          ]
        }
      ]
    }
  ]
}